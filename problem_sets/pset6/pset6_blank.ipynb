{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helpful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import requests\n",
    "import plotnine \n",
    "from plotnine import *\n",
    "import yaml\n",
    "\n",
    "## note: you may need to install some of these using !pip install\n",
    "## note that bitdotio has psycopg2 as a dependency so you'll need to either do:\n",
    "## !pip install psycopg2 or !pip install psycopg2-binary\n",
    "## see this issue for installation notes: https://github.com/rebeccajohnson88/PPOL564_slides_activities/issues/65\n",
    "import census\n",
    "from census import Census\n",
    "import us\n",
    "from us import states\n",
    "import bitdotio\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## print mult things\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "def load_creds(path: str):\n",
    "    with open(path, 'r') as stream:\n",
    "        try:\n",
    "            creds = yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "    return(creds)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep work: obtain an API key for the US Census (the American Community Survey)\n",
    "\n",
    "- Obtain a census API key from here: https://api.census.gov/data/key_signup.html \n",
    "- Place it in a credentials yaml file that also contains the API key with the key for the database API (shared on Canvas)\n",
    "- Documentation here for the `census` package on establishing an API connection: https://github.com/datamade/census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs and SQL (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Write a wrapper function to pull data from the NAEP API (12 points)\n",
    "\n",
    "In the class activity here: https://github.com/rebeccajohnson88/PPOL564_slides_activities/blob/main/activities/fall_22/solutions/10_apis_naep_yelp_solutions.ipynb\n",
    "\n",
    "We practiced pulling from the API for the National Assessment of Educational Progress (NAEP), \"America's report card\" of test scores. We pulled a small amount of data at the national level (writing scores by gender) using a query where the parameters were hardcoded.\n",
    "    \n",
    "In this problem, we'll practice pulling a larger set of data at the state level and writing a wrapper function.\n",
    "    \n",
    "As a reminder, the documentation for the NAEP API is here: https://www.nationsreportcard.gov/api_documentation.aspx\n",
    "\n",
    "The base link for writing queries is: https://www.nationsreportcard.gov/Dataservice/GetAdhocData.aspx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Write a query to pull 8th-grade mathematics scores in 2015 from the state of California (CA) by gender (1 point)\n",
    "\n",
    "- Subject: mathematics \n",
    "- Subscale: MRPCM composite scale \n",
    "- Grade: 8\n",
    "- Year: 2015\n",
    "- grouping variable: GENDER \n",
    "- Jurisdiction: CA \n",
    "\n",
    "Print the output in dataframe format and briefly interpret; what do scores look like between the genders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Write a query to pull 8th-grade mathematics scores in 2013, 2015, 2017, and 2019 from California by gender (1 point)\n",
    "\n",
    "Same as above but pull the years 2013, 2015, 2017, and 2019 (search documentation for how to pull multiple years in the same query) in one query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create a line plot to show variation in the scores across years (2 points)\n",
    "\n",
    "Using the results from 1.2, create a plot where the x axis has the year and the y axis is the math scores (`value` in dataframe), and there are separate lines/colors for male versus female students (`varValueLabel` in dataframe)\n",
    "\n",
    "Start the limits of the y axis at 270  and add informative labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Reproduce the queries from 1.1 and 1.2 using a user-defined function (4 points)\n",
    "\n",
    "Create a function, `construct_naep_query` that takes in two arguments:\n",
    "\n",
    "- year: this should be a list with all years (so if pulling one year, single element list; if multiple years, list with those years)\n",
    "- place: this should be a string with the name of the state or jurisdiction to pull \n",
    "    \n",
    "Have the function return the query and make sure it's identical to the queries you wrote for 1.1 and 1.2 (can use assert or other checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to execute function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Write and execute user-defined function that takes in a query and returns a pandas dataframe with the content of the response (4 points)\n",
    "\n",
    "- Write a user-defined function (`process_naep_query`) that takes in the NAEP query as a string, calls the API, and transforms the response into a pandas dataframe. Have the function return that pandas dataframe\n",
    "\n",
    "- Make sure the function is flexible enough to handle queries that return an error; for queries that return an error, have the function return the string \"Data not found; check your query\" (see solutions code for an example of try: except:)\n",
    "\n",
    "- Execute the function on the query that pulls 2013, 2015, 2017, and 2019 data (either from handwriting the query or the result in 1.4)\n",
    "\n",
    "- Print the resulting dataframe\n",
    "\n",
    "- Then execute the function on a query that pulls a state that doesn't exist (call this state ZZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explore data using SQL queries (22 points)\n",
    "\n",
    "In the previous example, you worked with the data in a flat file and manipulated it using pandas. Here, we're going to practice running queries to do some calculations using SQL --- in the case of our data, this is a bit overkill since the data are small but it is practice for larger datasets.\n",
    "\n",
    "- Database name: `rebeccajohnson88/ppol564_classdb`\n",
    "- Table name: `math_gencompare`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Load a creds file (0 points)\n",
    "\n",
    "Load a creds file that contains the two credentials you'll need for this and the next problem:\n",
    "\n",
    "- The credentials for our class database\n",
    "- The credentials for the Census API (see instructions above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = load_creds(\"PATH TO YOUR CREDS FILE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Establish a connection to the database (1 point)\n",
    "\n",
    "Note: if you get an error at this step, make sure you not only have bitdotio installed and imported but also its dependency psycopg2; we've also run into issues connecting on an unsecured (no password) wifi network so if you're on campus, try SaxaNet or eduroam\n",
    "\n",
    "Note: for full credit, when initializing the bitdotio connection, make sure to use the API key from the creds file you read in eg:\n",
    "`creds[class_database][api_key]` \n",
    "\n",
    "rather than hard-coding it in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Run a query to select all columns and the first 5 rows of the data to explore structure (2 points)\n",
    "\n",
    "Read the results in as a pandas dataframe and print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Find the (1) number of rows in the database, (2) number of distinct states,  (3) number of distinct years (3 points)\n",
    "\n",
    "Interpret the results - how do you think the data is structured in terms of states and years (eg long format where each state repeated; wide format)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Construct a new variable in the table, `is_male_higher` that takes the value of 1 if the math scores of males exceed that of females in that state and year (each row) (2 points)\n",
    "\n",
    "Read in the results, print the head, and find the mean across all rows (the percentage of state-years where male students have higher scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 group by year and find the percentage of states where male scores are higher than females (4 points)\n",
    "\n",
    "**A.** Write a query that (1) groups by year and (2) finds the percentage of states for that year where males have higher scores than females \n",
    "\n",
    "**B.** Interpret the results \n",
    "\n",
    "Hint: can either use subquery to construct the `is_male_higher` and use it or do it all in one query with a comparison; the `avg` command is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 group by state and find the percentage of years where male scores higher than females (4 points)\n",
    "\n",
    "A. Write a query that (1) groups by state and (2) finds the percentage of years for that state where males have higher scores than females\n",
    "\n",
    "B. Plot the results ordering the states from males higher all 4 years (prop = 1 or percent = 100%) to males higher none of the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Use a subquery to create an indicator and group by that indicator (6 points)\n",
    "\n",
    "The following states were the first 6 to expand the right to vote to women before the uniform federal expansion in 1920\n",
    "\n",
    "- Wyoming 1890\n",
    "- Colorado 1893\n",
    "- Utah 1896\n",
    "- Idaho 1896\n",
    "- Washington 1910\n",
    "- California 1911\n",
    "\n",
    "**A.** Create an indicator `is_early_vote` for whether a state is in that list or not; do so without typing the state names inside the string and instead collapsing the list and using format. Hint you can use format and a joined list: https://stackoverflow.com/questions/12007686/join-a-list-of-strings-in-python-and-wrap-each-string-in-quotation-marks \n",
    "\n",
    "**B.** Then, group by that indicator and year and find the percencentage of states in each group where males had higher scores than females \n",
    "\n",
    "**C.** Read the results and interpret. Does early expansion of voting seem to be correlated with girls scoring bearing on the math tests a century later?\n",
    "\n",
    "Hint: in order to group by the indicator in step b, you may need to use a subquery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we provide\n",
    "list_voting = [\"Wyoming\", \"Colorado\", \"Utah\", \"Idaho\", \"Washington\", \n",
    "                \"California\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pull state-level attributes using Census API (8 points)\n",
    "\n",
    "You want to explain the variation you see across states in gender gaps in test scores by looking at demographics of the state population. To do so, we'll pull demographics from the American Community Survey (ACS), a US Census data product discussed more here: https://en.wikipedia.org/wiki/American_Community_Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Obtain a Census API key, place it in credentials yaml, load the yaml file, and initialize connection to Census API using the `census` package  (0 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Run this function (feeding it your api connection) to get a list of variables to pull (0 points)\n",
    "\n",
    "Feed the connection to the API you created in previous step (if you print type it's a census.core.Census class) to the `your_connection` argument in the function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep in blank\n",
    "to_pull = ['RATIO OF INCOME TO POVERTY LEVEL OF FAMILIES IN THE PAST 12 MONTHS',\n",
    "          'ALLOCATION OF HOUSEHOLD INCOME IN THE PAST 12 MONTHS - PERCENT OF INCOME ALLOCATED',\n",
    "          'MEDIAN HOUSEHOLD INCOME IN THE PAST 12 MONTHS (IN 2018 INFLATION-ADJUSTED DOLLARS)',\n",
    "          'EDUCATIONAL ATTAINMENT FOR THE POPULATION 25 YEARS AND OVER',\n",
    "          'HOUSEHOLD TYPE (INCLUDING LIVING ALONE) BY RELATIONSHIP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep in blank\n",
    "def get_acs_varnames(your_connection):\n",
    "    \n",
    "    ## get tables for the acs 5-year estimates\n",
    "    all_tables = pd.DataFrame(your_connection.acs5.tables())\n",
    "    \n",
    "    ## specify the ones to pull\n",
    "    info_topull = all_tables[all_tables.description.isin(to_pull)].copy()\n",
    "    \n",
    "    ## use raw api to get varnames within those tables\n",
    "    all_vars = [pd.DataFrame(requests.get(one_table).json()['variables']).T\n",
    "                for one_table in info_topull.variables]\n",
    "    all_vars_df = pd.concat(all_vars)\n",
    "    all_vars_df['varname'] = all_vars_df.index\n",
    "    \n",
    "    ## subset to relevant\n",
    "    all_vars_df_subset = all_vars_df[['varname', 'group', 'label', 'concept']].copy()\n",
    "    all_vars_df_est = all_vars_df_subset[all_vars_df.varname.str.contains(\"E$\", \n",
    "                                        regex = True)].copy()\n",
    "    return(all_vars_df_est)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_cols = get_acs_varnames('INSERT YOUR CONNECTION HERE (an object)')\n",
    "acs_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Pull the variables for all 50 states (8 points)\n",
    "\n",
    "**A.** Use list comprehension to pull these variables for every state (each FIPS code) using the `acs5.state` method for the year 2013.\n",
    "- Hint: See the documentation for how to feed it variables to pull (requires a tuple); the documentation shows an example state--`MD`. You can find the other `FIPS` codes for states in the `states` object in `us` package you loaded above): https://github.com/datamade/census/blob/70e2c08710c1e10e5bc2054b78613fa8794d4765/README.rst\n",
    "\n",
    "**B.** Transform the result (which is a list of jsons) into a list of dataframes. Then concatenate and melt (on state) into one long-format dataframe\n",
    "\n",
    "**C.** First merge with the `all_states_fips` df, then merge that with `acs_cols` from 3.2 (on varname and variable) to know both which states the variables correspond to and the more informative variable names \n",
    "\n",
    "Call the final output `acs_df_forperc` so you can run the next code we provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this code- keep in blank\n",
    "## NOTE: you need to have the us package\n",
    "## installed and imported\n",
    "cols_pull = tuple(acs_cols.varname)\n",
    "all_states = states.STATES\n",
    "all_states_fips = pd.DataFrame({'FIPS':\n",
    "                                [one_state.fips for one_state in all_states],\n",
    "                               'state': [one_state.name for one_state in all_states],\n",
    "                               'abbrev': [one_state.abbr for one_state in all_states]})\n",
    "all_states_fips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 run code to transform counts into percentages (0 points)\n",
    "\n",
    "- Run the following code to transform the ACS counts in `acs_df_forperc` into percentages\n",
    "\n",
    "Note: You may see a warning from the str.split step; feel free to ignore it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_percentages(df, name_estimatecol = 'estimate'):\n",
    "    \n",
    "    ## remove cols that dont need percentages\n",
    "    df_forperc = df[~df.perc_NA].copy()\n",
    "    \n",
    "    ## group by location and variable prefix \n",
    "    group_co_tract_varg = df_forperc.groupby(['FIPS', 'variable_prefix'])\n",
    "    \n",
    "    ## iterate over groups\n",
    "    df_longperc = []\n",
    "    for group, data_raw in group_co_tract_varg:\n",
    "        prefix = data_raw.variable_prefix.iloc[0]\n",
    "        FIPS = data_raw.FIPS.iloc[0]\n",
    "        row_list_group = []\n",
    "        data = data_raw.sort_values(by = 'variable_suffix')\n",
    "        for i in range(1, data.shape[0]):\n",
    "            numerator = data[name_estimatecol].iloc[i]\n",
    "            denominator = float(data[name_estimatecol].iloc[0])\n",
    "            if denominator == 0:\n",
    "                denominator = np.nan\n",
    "            if denominator != 0:\n",
    "                percentage = numerator / denominator\n",
    "                row = [prefix, FIPS]\n",
    "                row = row + [data.variable_suffix.iloc[i], percentage]\n",
    "                row_list_group.append(row)\n",
    "        df_longperc.append(pd.DataFrame(row_list_group))\n",
    "    percentages_all_groups = pd.concat(df_longperc)\n",
    "    percentages_all_groups.columns = ['variable_prefix',\"FIPS\",\n",
    "                                  'variable_suffix', 'percentage']\n",
    "    percentages_all_groups['percentage'] = percentages_all_groups.percentage.astype(float)\n",
    "    return(percentages_all_groups)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames_percnotrelevant = [\"B19013_001E\"]\n",
    "\n",
    "## create prefix and suffix columns\n",
    "acs_df_forperc['variable_prefix'], acs_df_forperc['variable_suffix'] = \\\n",
    "                                acs_df_forperc['varname'].str.split('_', 1).str\n",
    "acs_df_forperc['perc_NA'] = np.where(acs_df_forperc.varname.isin(varnames_percnotrelevant),\n",
    "                                  True, False)\n",
    "acs_df_forperc = acs_df_forperc[acs_df_forperc.variable != \"GEO_ID\"].copy()\n",
    "\n",
    "perc_long = create_percentages(acs_df_forperc, 'value').sort_values(by = 'variable_prefix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_long_wnames = pd.merge(perc_long,\n",
    "                           acs_df_forperc,\n",
    "                           on = ['variable_prefix', 'variable_suffix', 'FIPS'],\n",
    "                           how = \"right\")\n",
    "perc_long_wnames['value'] = perc_long_wnames.value.astype(float)\n",
    "\n",
    "perc_long_wnames['percentage'] = np.where(perc_long_wnames.perc_NA,\n",
    "                                         perc_long_wnames.value,\n",
    "                                         perc_long_wnames.percentage)\n",
    "perc_long_wnames['varname_words'] = \"acspredict_\" + perc_long_wnames.concept.str.replace(\"\\s+|\\(|\\)\", \"_\", \n",
    "                                    regex = True).str.lower() + \\\n",
    "                            perc_long_wnames.label.str.replace(\"\\.|\\!|\\,|\\(|\\)|\\-\", \n",
    "                                    \"\", regex = True).str.lower() \n",
    "\n",
    "perc_long_wnames_final = perc_long_wnames[['FIPS', 'percentage', \n",
    "                                          'varname_words']].copy()\n",
    "\n",
    "\n",
    "perc_wide = pd.pivot_table(perc_long_wnames_final, \n",
    "                           index = 'FIPS',\n",
    "                          columns='varname_words',\n",
    "                            values='percentage').reset_index()\n",
    "\n",
    "## merge state info back on\n",
    "perc_wide_wstate = pd.merge(perc_wide,\n",
    "                           all_states_fips,\n",
    "                           on = \"FIPS\",\n",
    "                           how = \"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_wide_wstate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 extra credit (2 points)\n",
    "\n",
    "Use list comprehension and NAEP query creation/process results functions you created above to iterate over state abbreviations in `all_states_fips` and pull the same test score gap information\n",
    "\n",
    "If skipping, you'll read in pkl at next step\n",
    "\n",
    "**Note**: this took 2 mins to run on my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Explore variation in math score disparities and trends (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 If you didn't complete the extra credit, read in the `acs_wmath.pkl` file (csv is backup) (0 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Create a visualization where one axis is the state; the other axis is the male 2013 math scores - the female 2013 math scores (gender disparity) (2 points)\n",
    "\n",
    "\n",
    "You have free rein over additional details but make sure it is informative over what direction of disparity positive versus negative values mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Examine gender disparity in relation to household income (6 points)\n",
    "\n",
    "**A.** Construct an indicator variable for the state having better performance of males in 2013 than females\n",
    "\n",
    "**B.** First plot a smoothed scatterplot of estimated median household income from the acs data (we provide varname below) vs `math_male_2013`. Then do a second smoothed scatterplot for median household income vs `math_female_2013`.\n",
    "\n",
    "**C.** \n",
    "Then use the `np.corrcoef` command (three separate times) to examine the bivariate correlation of\n",
    "- male performance\n",
    "- female performance\n",
    "- the indicator variable from **A** \n",
    "\n",
    "with median household income (`acspredict_median_household_income_in_the_past_12_months__in_2018_inflation-adjusted_dollars_estimatemedian household income in the past 12 months in 2018 inflationadjusted dollars`)\n",
    "\n",
    "Documentation: https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html\n",
    "\n",
    "**D.** Interpret the correlations:\n",
    "   - Do boys in states with higher median household income (MHI) tend to perform better than boys in states with lower MHI?\n",
    "   - Do girls in states with higher MHI tend to perform better than girls in states with lower MHI?\n",
    "   - Is the male performance advantage over girls higher or lower in states with higher MHI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "865fd703f6b7a19729d00bc4a0ae404ed58594dc540c288af8d80981eb08885c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
